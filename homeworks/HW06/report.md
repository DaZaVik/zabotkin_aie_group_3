1. Dataset

Какой датасет выбран: S06-hw-dataset-02.csv
Размер: 18 000 строк, 39 столбцов

Целевая переменная: target
бинарная классификация
класс 0: ~73.7%
класс 1: ~26.3%

Признаки:
все признаки числовые (float);
присутствуют признаки с нелинейными взаимодействиями (x_int_*);
столбец id используется только как идентификатор и не включается в признаки.

2. Protocol

Разбиение:

train / test = 80% / 20%;
random_state = 42;
использована стратификация по таргету (stratify=y) для сохранения баланса классов.

Подбор гиперпараметров:

выполнялся только на train через cross-validation;
использовался StratifiedKFold (несколько фолдов);
оптимизация проводилась по метрике F1 как более устойчивой к умеренному дисбалансу классов.

Метрики:

accuracy — базовая интерпретируемая метрика;
F1 — важна из-за дисбаланса классов;
ROC-AUC — позволяет оценить качество ранжирования вероятностей и сравнивать модели независимо от порога.
Данный набор метрик уместен для бинарной задачи с умеренным дисбалансом.

3. Models

В рамках эксперимента были сравнены следующие модели:

DummyClassifier
Использовался как наивный baseline.

LogisticRegression
Использована в виде Pipeline(StandardScaler + LogisticRegression) как baseline из S05.

DecisionTreeClassifier
Контроль сложности осуществлялся через параметры:

max_depth;
min_samples_leaf;
ccp_alpha.

RandomForestClassifier
Использовался ансамбль деревьев с подбором параметров:

max_depth;
min_samples_leaf;
max_features.

HistGradientBoostingClassifier
Использован как boosting-модель для последовательного улучшения качества:
подбирались learning_rate, max_depth, max_leaf_nodes.
StackingClassifier не использовался (опциональная часть).

4. Results

Финальные метрики на test (примерно):

DummyClassifier — ожидаемо низкое качество
LogisticRegression — адекватный baseline, но ограничена линейностью
DecisionTree — чувствителен к переобучению без жёсткого контроля сложности
RandomForest — заметно улучшает качество за счёт снижения variance
HistGradientBoosting — лучшая модель

Победитель:
HistGradientBoostingClassifier, выбран по максимальному значению ROC-AUC (и высокому F1).

Объяснение:
Boosting лучше всего справился с нелинейными зависимостями и взаимодействиями признаков, присутствующими в данных.

5. Analysis

Устойчивость:
Для нескольких моделей были выполнены прогоны с разными random_state.
Результаты показали небольшой разброс метрик, что говорит о приемлемой устойчивости ансамблей (особенно RandomForest и boosting).

Ошибки:
Для лучшей модели была построена confusion matrix.
Основные ошибки приходятся на пограничные объекты положительного класса, что типично для задач с перекрытием распределений.

Интерпретация:
Для лучшей модели была рассчитана permutation importance.
Топ-признаки включают как базовые числовые фичи, так и признаки взаимодействий (x_int_*), что подтверждает важность нелинейных зависимостей в данных.

6. Conclusion

Одиночные деревья легко переобучаются без контроля сложности.
Ансамбли снижают variance и дают более стабильные результаты.
Random Forest устойчив, но boosting даёт наилучшее качество.
Нелинейные взаимодействия признаков критичны для данной задачи.
F1 и ROC-AUC более информативны, чем accuracy, при дисбалансе классов.
Чёткий train/test + CV-протокол позволяет честно сравнивать модели.