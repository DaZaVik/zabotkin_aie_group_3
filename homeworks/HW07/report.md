1. Datasets

В работе был использован один синтетический датасет из предоставленных.

Файл: S07-hw-dataset-02.csv
Размер: ~8000 строк, 4 столбца
Признаки: числовые
Пропуски: отсутствуют
"Подлости" датасета:
нелинейная структура кластеров;
наличие выбросов;
присутствует шумовой признак;
предположение KMeans о "шарообразных" кластерах нарушается.



2. Protocol

Использовался "честный" unsupervised-протокол, одинаковый для всех сравниваемых моделей.

Препроцессинг:
числовые признаки: StandardScaler;
пропуски отсутствовали, поэтому imputation не применялась;
PCA применялась только для визуализации, не для обучения моделей.

Поиск гиперпараметров:
KMeans: перебор числа кластеров k в диапазоне от 2 до 20;
DBSCAN: перебор параметра eps в разумном диапазоне после масштабирования, min_samples фиксировался;
лучшая конфигурация выбиралась по внутренним метрикам, в первую очередь по silhouette_score.

Метрики качества:
silhouette_score (выше — лучше);
davies_bouldin_score (ниже — лучше);
calinski_harabasz_score (выше — лучше);
для DBSCAN метрики считались только на non-noise точках, доля шума анализировалась отдельно.
Визуализация:

PCA(2D) scatter для лучшего решения;
графики подбора параметров (silhouette vs k и silhouette vs eps).

3. Models

Для датасета были сравнены следующие алгоритмы:

KMeans:
подбор числа кластеров k;
фиксированы random_state и n_init.

DBSCAN:
подбор параметра eps;
анализ доли шума (label = -1).

4. Results

Лучший метод и параметры:
DBSCAN (eps ≈ 0.4–0.6, min_samples ≈ 5)
Метрики:
silhouette (на non-noise точках) — выше, чем у KMeans;
Davies-Bouldin — ниже;
Calinski-Harabasz — выше.

Доля шума:
Присутствует умеренная доля шума, соответствующая выбросам в данных.

Комментарий:
DBSCAN оказался более уместным, так как способен выявлять кластеры сложной формы и корректно обрабатывать выбросы, которые KMeans принудительно относит к ближайшему кластеру.

5. Analysis
5.1 Сравнение алгоритмов

KMeans плохо справляется с нелинейной структурой кластеров и выбросами;
DBSCAN более устойчив к шуму и лучше отражает истинную структуру данных
масштабирование признаков критически важно для корректной работы distance-based методов.

5.2 Устойчивость

Для датасета была проведена мини-проверка устойчивости KMeans:
выполнено несколько запусков с разными random_state;
сравнение разбиений показало близкие результаты.

Вывод:
Разбиения KMeans достаточно устойчивы, однако качество кластеризации ограничено предположениями модели.

5.3 Интерпретация кластеров
Интерпретация проводилась с помощью:
визуализации в пространстве первых двух компонент PCA;
анализа плотности и взаимного расположения кластеров.
DBSCAN выявляет компактные плотные группы и корректно отделяет шумовые точки.

6. Conclusion

Кластеризация без меток требует аккуратного и воспроизводимого протокола.
Масштабирование признаков является обязательным шагом.
Внутренние метрики нужно интерпретировать совместно.
DBSCAN предпочтителен для данных с шумом и нелинейной структурой.
KMeans эффективен только при выполнении его геометрических предположений.
PCA полезна для интерпретации результатов, но не для оценки качества.